"""
Tesla Fleet Simulator - Enterprise Scale Processing
===================================================

Advanced multi-threaded fleet simulation demonstrating Tesla's global 
vehicle monitoring at production scale with sophisticated analytics.

Features:
- Generate 1000+ virtual Tesla vehicles across global markets
- Multi-threaded parallel processing simulation  
- Real-time anomaly detection at enterprise scale
- Performance benchmarking and scalability analysis
- Geographic distribution modeling
- Production deployment assessment
"""

import threading
import time
import json
import numpy as np
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from typing import List, Dict, Any
import random
from pathlib import Path

@dataclass
class TeslaVehicle:
    """Comprehensive Tesla vehicle data structure"""
    vehicle_id: str
    model: str
    production_year: int
    market: str
    location: Dict[str, float]  # lat, lon
    mileage: int
    battery_health: float
    software_version: str
    
    # NVH-specific attributes
    engine_baseline_noise: float
    suspension_wear: float
    brake_condition: float
    motor_efficiency: float
    
    # Operational status
    last_diagnostic: datetime
    service_history: List[str]
    anomaly_history: List[Dict[str, Any]]

class TeslaFleetGenerator:
    """
    Tesla Global Fleet Generator
    
    Creates realistic fleet distributions across Tesla's global markets
    with authentic vehicle characteristics and operational patterns.
    """
    
    def __init__(self, fleet_size: int = 1500):
        self.fleet_size = fleet_size
        
        # Tesla global market distribution percentages:
        self.market_distribution = {
            'North America': 0.45,  # US, Canada  
            'Europe': 0.25,         # EU, UK, Norway
            'China': 0.20,          # China market
            'Asia Pacific': 0.07,   # Australia, Japan, South Korea
            'Other': 0.03           # Other emerging markets
        }
        
        # Tesla model distribution by market
        self.model_distribution = {
            'Model 3': 0.45,
            'Model Y': 0.30, 
            'Model S': 0.15,
            'Model X': 0.08,
            'Cybertruck': 0.02
        }
        
        # Global Tesla locations (major markets)
        self.tesla_locations = {
            'North America': [
                {'name': 'Fremont, CA', 'lat': 37.5485, 'lon': -121.9886},
                {'name': 'Austin, TX', 'lat': 30.2672, 'lon': -97.7431}, 
                {'name': 'Buffalo, NY', 'lat': 42.8864, 'lon': -78.8784},
                {'name': 'Reno, NV', 'lat': 39.5296, 'lon': -119.8138},
                {'name': 'Toronto, Canada', 'lat': 43.6532, 'lon': -79.3832}
            ],
            'Europe': [
                {'name': 'Berlin, Germany', 'lat': 52.5200, 'lon': 13.4050},
                {'name': 'Tilburg, Netherlands', 'lat': 51.5555, 'lon': 5.0913},
                {'name': 'Oslo, Norway', 'lat': 59.9139, 'lon': 10.7522},
                {'name': 'London, UK', 'lat': 51.5074, 'lon': -0.1278},
                {'name': 'Paris, France', 'lat': 48.8566, 'lon': 2.3522}
            ],
            'China': [
                {'name': 'Shanghai Gigafactory', 'lat': 31.2304, 'lon': 121.4737},
                {'name': 'Beijing', 'lat': 39.9042, 'lon': 116.4074},
                {'name': 'Shenzhen', 'lat': 22.3193, 'lon': 114.1694},
                {'name': 'Guangzhou', 'lat': 23.1291, 'lon': 113.2644}
            ],
            'Asia Pacific': [
                {'name': 'Sydney, Australia', 'lat': -33.8688, 'lon': 151.2093},
                {'name': 'Tokyo, Japan', 'lat': 35.6762, 'lon': 139.6503},
                {'name': 'Seoul, South Korea', 'lat': 37.5665, 'lon': 126.9780}
            ],
            'Other': [
                {'name': 'Dubai, UAE', 'lat': 25.2048, 'lon': 55.2708},
                {'name': 'Tel Aviv, Israel', 'lat': 32.0853, 'lon': 34.7818}
            ]
        }
    
    def generate_fleet(self) -> List[TeslaVehicle]:
        """Generate comprehensive Tesla fleet with realistic distribution"""
        
        print(f" Generating Tesla Global Fleet ({self.fleet_size:,} vehicles)...")
        print("=" * 60)
        
        fleet = []
        vehicle_counter = 1
        
        # Progress tracking
        progress_milestones = [0.25, 0.5, 0.75, 1.0]
        current_milestone = 0
        
        for i in range(self.fleet_size):
            # Progress reporting
            progress = (i + 1) / self.fleet_size
            if (current_milestone < len(progress_milestones) and 
                progress >= progress_milestones[current_milestone]):
                print(f"   Progress: {progress*100:.0f}% ({i+1:,}/{self.fleet_size:,} vehicles)")
                current_milestone += 1
            
            # Select market based on distribution
            market = np.random.choice(
                list(self.market_distribution.keys()),
                p=list(self.market_distribution.values())
            )
            
            # Select Tesla model based on distribution
            model = np.random.choice(
                list(self.model_distribution.keys()),
                p=list(self.model_distribution.values())
            )
            
            # Select location within market
            location_data = np.random.choice(self.tesla_locations[market])
            
            # Add some geographic dispersion (vehicles spread around service centers)
            lat_offset = np.random.uniform(-2, 2)  # Â±2 degrees
            lon_offset = np.random.uniform(-2, 2)
            
            location = {
                'name': location_data['name'],
                'lat': location_data['lat'] + lat_offset,
                'lon': location_data['lon'] + lon_offset
            }
            
            # Generate realistic vehicle characteristics
            production_year = self._generate_production_year(model)
            mileage = self._generate_mileage(model, production_year)
            
            # Vehicle ID generation (Tesla-like format)
            model_prefix = {
                'Model 3': 'T3',
                'Model Y': 'TY', 
                'Model S': 'TS',
                'Model X': 'TX',
                'Cybertruck': 'CT'
            }[model]
            
            vehicle_id = f"{model_prefix}-{vehicle_counter:04d}"
            
            # Generate comprehensive vehicle data
            vehicle = TeslaVehicle(
                vehicle_id=vehicle_id,
                model=model,
                production_year=production_year,
                market=market,
                location=location,
                mileage=mileage,
                battery_health=self._generate_battery_health(mileage, production_year),
                software_version=self._generate_software_version(),
                
                # NVH characteristics
                engine_baseline_noise=np.random.uniform(45, 65),
                suspension_wear=self._generate_wear_factor(mileage),
                brake_condition=self._generate_wear_factor(mileage, component='brake'),
                motor_efficiency=self._generate_motor_efficiency(model, mileage),
                
                # Operational data
                last_diagnostic=self._generate_last_diagnostic(),
                service_history=self._generate_service_history(mileage),
                anomaly_history=[]
            )
            
            fleet.append(vehicle)
            vehicle_counter += 1
        
        self._print_fleet_statistics(fleet)
        return fleet
    
    def _generate_production_year(self, model: str) -> int:
        """Generate realistic production year based on model"""
        current_year = datetime.now().year
        
        model_intro_years = {
            'Model S': 2012,
            'Model X': 2015,
            'Model 3': 2017,
            'Model Y': 2020,
            'Cybertruck': 2024
        }
        
        intro_year = model_intro_years[model]
        # Weight towards more recent years
        years = list(range(intro_year, current_year + 1))
        weights = np.exp(np.linspace(0, 2, len(years)))  # Exponential weighting
        weights = weights / weights.sum()
        
        return np.random.choice(years, p=weights)
    
    def _generate_mileage(self, model: str, production_year: int) -> int:
        """Generate realistic mileage based on age and model"""
        age = datetime.now().year - production_year
        
        # Average miles per year by model type
        annual_mileage = {
            'Model S': 15000,  # Executive/luxury usage
            'Model X': 12000,  # Family SUV usage
            'Model 3': 18000,  # Daily commuter
            'Model Y': 16000,  # Popular crossover
            'Cybertruck': 8000  # New model, limited usage
        }[model]
        
        # Add variance and ensure realistic bounds
        base_mileage = annual_mileage * age
        variance = np.random.uniform(0.7, 1.3)  # Â±30% variance
        mileage = int(base_mileage * variance)
        
        return max(0, min(mileage, 300000))  # Cap at 300k miles
    
    def _generate_battery_health(self, mileage: int, production_year: int) -> float:
        """Generate realistic battery health based on age and usage"""
        age = datetime.now().year - production_year
        
        # Battery degradation model
        age_degradation = age * 0.02  # 2% per year
        mileage_degradation = mileage / 100000 * 0.08  # 8% per 100k miles
        
        # Random variance in battery quality
        quality_variance = np.random.uniform(-0.05, 0.05)
        
        health = 1.0 - age_degradation - mileage_degradation + quality_variance
        return max(0.6, min(health, 1.0))  # Clamp between 60-100%
    
    def _generate_software_version(self) -> str:
        """Generate realistic Tesla software version"""
        major_versions = [2024, 2023, 2022]
        major = np.random.choice(major_versions, p=[0.6, 0.3, 0.1])
        minor = np.random.randint(1, 48)  # Weekly updates
        patch = np.random.randint(0, 10)
        
        return f"{major}.{minor:02d}.{patch}"
    
    def _generate_wear_factor(self, mileage: int, component: str = 'suspension') -> float:
        """Generate component wear factor"""
        base_wear = mileage / 150000  # Base wear over 150k miles
        
        # Component-specific wear rates
        wear_multipliers = {
            'suspension': 1.0,
            'brake': 1.5,  # Brakes wear faster
            'motor': 0.7   # Electric motors last longer
        }
        
        multiplier = wear_multipliers.get(component, 1.0)
        wear = base_wear * multiplier * np.random.uniform(0.8, 1.2)
        
        return min(wear, 1.0)  # Cap at 100% wear
    
    def _generate_motor_efficiency(self, model: str, mileage: int) -> float:
        """Generate motor efficiency based on model and wear"""
        base_efficiency = {
            'Model S': 0.94,
            'Model X': 0.91, 
            'Model 3': 0.93,
            'Model Y': 0.92,
            'Cybertruck': 0.95
        }[model]
        
        # Efficiency degradation with mileage
        degradation = mileage / 200000 * 0.05  # 5% over 200k miles
        efficiency = base_efficiency - degradation + np.random.uniform(-0.02, 0.02)
        
        return max(0.8, min(efficiency, 0.98))
    
    def _generate_last_diagnostic(self) -> datetime:
        """Generate last diagnostic timestamp"""
        days_ago = np.random.randint(0, 90)  # Within last 90 days
        return datetime.now() - timedelta(days=days_ago)
    
    def _generate_service_history(self, mileage: int) -> List[str]:
        """Generate realistic service history"""
        services = []
        
        # Service frequency based on mileage
        service_count = mileage // 25000  # Service every 25k miles
        
        possible_services = [
            "Routine Maintenance",
            "Tire Rotation", 
            "Brake Inspection",
            "Software Update",
            "Battery Calibration",
            "Alignment Check",
            "HVAC Service",
            "Door Handle Replacement",
            "Screen Replacement"
        ]
        
        for _ in range(min(service_count, 8)):  # Max 8 services
            services.append(np.random.choice(possible_services))
        
        return services
    
    def _print_fleet_statistics(self, fleet: List[TeslaVehicle]):
        """Print comprehensive fleet generation statistics"""
        
        print(f"\n Tesla Global Fleet Generation Complete!")
        print("=" * 60)
        
        # Market distribution analysis
        print(f"\n GLOBAL MARKET DISTRIBUTION:")
        market_counts = {}
        for vehicle in fleet:
            market_counts[vehicle.market] = market_counts.get(vehicle.market, 0) + 1
        
        for market, count in sorted(market_counts.items(), key=lambda x: x[1], reverse=True):
            percentage = count / len(fleet) * 100
            print(f"   {market:15} {count:6,} vehicles ({percentage:5.1f}%)")
        
        # Model distribution analysis  
        print(f"\n MODEL DISTRIBUTION:")
        model_counts = {}
        for vehicle in fleet:
            model_counts[vehicle.model] = model_counts.get(vehicle.model, 0) + 1
        
        for model, count in sorted(model_counts.items(), key=lambda x: x[1], reverse=True):
            percentage = count / len(fleet) * 100
            print(f"   {model:12} {count:6,} vehicles ({percentage:5.1f}%)")
        
        # Age and mileage analysis
        ages = [datetime.now().year - v.production_year for v in fleet]
        mileages = [v.mileage for v in fleet]
        
        print(f"\n FLEET CHARACTERISTICS:")
        print(f"   Average Age: {np.mean(ages):.1f} years")
        print(f"   Average Mileage: {np.mean(mileages):,.0f} miles")
        print(f"   Newest Vehicle: {min(ages)} years old")
        print(f"   Oldest Vehicle: {max(ages)} years old")
        print(f"   Highest Mileage: {max(mileages):,} miles")
        
        # Battery health analysis
        battery_healths = [v.battery_health for v in fleet]
        print(f"\n BATTERY HEALTH ANALYSIS:")
        print(f"   Average Health: {np.mean(battery_healths):.1%}")
        print(f"   Vehicles >95% Health: {len([h for h in battery_healths if h > 0.95]):,}")
        print(f"   Vehicles <80% Health: {len([h for h in battery_healths if h < 0.80]):,}")

class TeslaFleetProcessor:
    """
    Enterprise Tesla Fleet Processing Engine
    
    Simulates large-scale fleet diagnostics processing with multi-threading,
    performance monitoring, and production-grade analytics.
    """
    
    def __init__(self, max_workers: int = 25):
        self.max_workers = max_workers
        self.processing_stats = {
            'total_processed': 0,
            'successful_diagnostics': 0,
            'anomalies_detected': 0,
            'errors_encountered': 0,
            'processing_times': []
        }
    
    def process_vehicle_diagnostic(self, vehicle: TeslaVehicle) -> Dict[str, Any]:
        """
        Simulate comprehensive vehicle diagnostic processing
        
        Includes NVH analysis, anomaly detection, and performance assessment
        """
        start_time = time.time()
        
        try:
            # Simulate realistic processing time (with variance)
            base_processing_time = np.random.uniform(0.015, 0.035)  # 15-35ms base
            
            # Add complexity based on vehicle characteristics
            if vehicle.mileage > 100000:
                base_processing_time += 0.005  # High mileage takes longer
            
            if len(vehicle.service_history) > 5:
                base_processing_time += 0.003  # Complex history takes longer
            
            # Simulate processing delay
            time.sleep(base_processing_time)
            
            # Generate comprehensive diagnostic results
            diagnostic_result = self._generate_diagnostic_result(vehicle)
            
            # Update processing statistics
            self.processing_stats['total_processed'] += 1
            self.processing_stats['successful_diagnostics'] += 1
            
            if diagnostic_result['anomaly_detected']:
                self.processing_stats['anomalies_detected'] += 1
            
            processing_time = (time.time() - start_time) * 1000  # Convert to ms
            self.processing_stats['processing_times'].append(processing_time)
            
            return diagnostic_result
            
        except Exception as e:
            # Handle processing errors gracefully
            self.processing_stats['errors_encountered'] += 1
            
            return {
                'vehicle_id': vehicle.vehicle_id,
                'status': 'ERROR',
                'error': str(e),
                'processing_time_ms': (time.time() - start_time) * 1000
            }
    
    def _generate_diagnostic_result(self, vehicle: TeslaVehicle) -> Dict[str, Any]:
        """Generate comprehensive diagnostic analysis"""
        
        # Base anomaly probability calculation
        anomaly_probability = 0.0
        
        # Age-based deterioration
        age = datetime.now().year - vehicle.production_year
        anomaly_probability += age * 0.02
        
        # Mileage-based wear
        anomaly_probability += vehicle.mileage / 200000 * 0.3
        
        # Component-specific factors
        anomaly_probability += (1 - vehicle.battery_health) * 0.4
        anomaly_probability += vehicle.suspension_wear * 0.2
        anomaly_probability += vehicle.brake_condition * 0.25
        
        # Model-specific adjustments
        model_risk_factors = {
            'Model S': 0.05,  # Luxury model, more complex
            'Model X': 0.08,  # Falcon doors, complexity
            'Model 3': 0.02,  # Reliable, mass production
            'Model Y': 0.03,  # Newer design
            'Cybertruck': 0.10  # New model, early issues
        }
        anomaly_probability += model_risk_factors.get(vehicle.model, 0.05)
        
        # Add random variance
        anomaly_probability += np.random.uniform(-0.1, 0.1)
        
        # Clamp probability
        anomaly_probability = max(0.0, min(anomaly_probability, 1.0))
        
        # Determine health status
        if anomaly_probability > 0.7:
            health_status = "CRITICAL"
            needs_service = True
            priority = "HIGH"
        elif anomaly_probability > 0.4:
            health_status = "WARNING"
            needs_service = True  
            priority = "MEDIUM"
        else:
            health_status = "NORMAL"
            needs_service = False
            priority = "LOW"
        
        # Generate specific diagnostic findings
        diagnostic_findings = self._generate_diagnostic_findings(vehicle, anomaly_probability)
        
        return {
            'vehicle_id': vehicle.vehicle_id,
            'model': vehicle.model,
            'market': vehicle.market,
            'location': vehicle.location['name'],
            'anomaly_probability': round(anomaly_probability, 3),
            'health_status': health_status,
            'needs_service': needs_service,
            'priority': priority,
            'anomaly_detected': anomaly_probability > 0.5,
            'diagnostic_findings': diagnostic_findings,
            'battery_health': vehicle.battery_health,
            'mileage': vehicle.mileage,
            'last_service': vehicle.last_diagnostic.isoformat(),
            'processing_timestamp': datetime.now().isoformat()
        }
    
    def _generate_diagnostic_findings(self, vehicle: TeslaVehicle, anomaly_prob: float) -> List[str]:
        """Generate specific diagnostic findings based on vehicle condition"""
        
        findings = []
        
        # Battery-related findings
        if vehicle.battery_health < 0.85:
            findings.append(f"Battery degradation detected: {vehicle.battery_health:.1%} capacity")
        
        # Mileage-related findings
        if vehicle.mileage > 150000:
            findings.append(f"High mileage vehicle: {vehicle.mileage:,} miles")
        
        # Suspension findings
        if vehicle.suspension_wear > 0.6:
            findings.append("Suspension system showing wear patterns")
        
        # Brake findings  
        if vehicle.brake_condition > 0.7:
            findings.append("Brake system requires attention")
        
        # Motor efficiency findings
        if vehicle.motor_efficiency < 0.88:
            findings.append(f"Motor efficiency below optimal: {vehicle.motor_efficiency:.1%}")
        
        # Age-related findings
        age = datetime.now().year - vehicle.production_year
        if age > 7:
            findings.append(f"Aging vehicle ({age} years old) - increased monitoring recommended")
        
        # Model-specific findings
        if vehicle.model == "Model X" and anomaly_prob > 0.5:
            findings.append("Falcon door mechanism inspection recommended")
        elif vehicle.model == "Cybertruck" and anomaly_prob > 0.3:
            findings.append("Early production model - enhanced diagnostics applied")
        
        # Add generic findings if anomaly detected but no specific issues
        if anomaly_prob > 0.5 and not findings:
            findings.append("General anomaly pattern detected - comprehensive inspection recommended")
        
        return findings
    
    def process_fleet_parallel(self, fleet: List[TeslaVehicle]) -> Dict[str, Any]:
        """
        Process entire Tesla fleet using multi-threading for enterprise scale
        """
        print(f"\n Processing Tesla Fleet with {self.max_workers} parallel threads...")
        print("=" * 60)
        
        start_time = time.time()
        results = []
        
        # Process fleet in parallel batches
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # Submit all tasks
            future_to_vehicle = {
                executor.submit(self.process_vehicle_diagnostic, vehicle): vehicle 
                for vehicle in fleet
            }
            
            # Process completed tasks
            completed = 0
            for future in as_completed(future_to_vehicle):
                vehicle = future_to_vehicle[future]
                
                try:
                    result = future.result()
                    results.append(result)
                    completed += 1
                    
                    # Progress reporting
                    if completed % 200 == 0 or completed == len(fleet):
                        progress = completed / len(fleet) * 100
                        elapsed = time.time() - start_time
                        rate = completed / elapsed if elapsed > 0 else 0
                        print(f"   Progress: {progress:5.1f}% ({completed:,}/{len(fleet):,}) | "
                              f"Rate: {rate:.1f} vehicles/sec")
                
                except Exception as e:
                    print(f"   Error processing {vehicle.vehicle_id}: {e}")
                    self.processing_stats['errors_encountered'] += 1
        
        total_time = time.time() - start_time
        
        # Generate comprehensive processing summary
        processing_summary = self._generate_processing_summary(results, total_time)
        
        return {
            'results': results,
            'processing_summary': processing_summary,
            'performance_metrics': self._calculate_performance_metrics(total_time, len(fleet))
        }
    
    def _generate_processing_summary(self, results: List[Dict], total_time: float) -> Dict[str, Any]:
        """Generate comprehensive processing analysis"""
        
        # Health status distribution
        health_distribution = {}
        for result in results:
            if 'health_status' in result:
                status = result['health_status']
                health_distribution[status] = health_distribution.get(status, 0) + 1
        
        # Anomaly analysis
        anomaly_scores = [r['anomaly_probability'] for r in results if 'anomaly_probability' in r]
        anomalies_detected = len([r for r in results if r.get('anomaly_detected', False)])
        
        # Market analysis
        market_distribution = {}
        for result in results:
            if 'market' in result:
                market = result['market']
                market_distribution[market] = market_distribution.get(market, 0) + 1
        
        # Service needs analysis
        service_needed = len([r for r in results if r.get('needs_service', False)])
        
        return {
            'total_vehicles_processed': len(results),
            'processing_time_seconds': round(total_time, 2),
            'health_distribution': health_distribution,
            'anomaly_statistics': {
                'total_anomalies': anomalies_detected,
                'anomaly_rate': round(anomalies_detected / len(results) * 100, 1) if results else 0,
                'mean_score': round(np.mean(anomaly_scores), 3) if anomaly_scores else 0,
                'median_score': round(np.median(anomaly_scores), 3) if anomaly_scores else 0,
                'std_score': round(np.std(anomaly_scores), 3) if anomaly_scores else 0,
                'max_score': round(max(anomaly_scores), 3) if anomaly_scores else 0,
                'vehicles_over_threshold': len([s for s in anomaly_scores if s > 0.5])
            },
            'market_distribution': market_distribution,
            'service_analysis': {
                'vehicles_needing_service': service_needed,
                'service_rate': round(service_needed / len(results) * 100, 1) if results else 0
            }
        }
    
    def _calculate_performance_metrics(self, total_time: float, vehicle_count: int) -> Dict[str, Any]:
        """Calculate comprehensive performance metrics"""
        
        processing_times = self.processing_stats['processing_times']
        
        return {
            'total_time': round(total_time, 2),
            'throughput_per_second': round(vehicle_count / total_time, 2) if total_time > 0 else 0,
            'average_latency_ms': round(np.mean(processing_times), 2) if processing_times else 0,
            'median_latency_ms': round(np.median(processing_times), 2) if processing_times else 0,
            'p95_latency_ms': round(np.percentile(processing_times, 95), 2) if processing_times else 0,
            'p99_latency_ms': round(np.percentile(processing_times, 99), 2) if processing_times else 0,
            'peak_latency_ms': round(max(processing_times), 2) if processing_times else 0,
            'min_latency_ms': round(min(processing_times), 2) if processing_times else 0,
            'total_processed': self.processing_stats['total_processed'],
            'successful_diagnostics': self.processing_stats['successful_diagnostics'],
            'error_count': self.processing_stats['errors_encountered'],
            'success_rate': round(
                self.processing_stats['successful_diagnostics'] / 
                max(self.processing_stats['total_processed'], 1) * 100, 2
            )
        }

def create_fleet_report(fleet: List[TeslaVehicle], processing_results: Dict[str, Any]):
    """Generate comprehensive Tesla fleet management report"""
    
    print(f"\n" + "="*70)
    print(f" TESLA GLOBAL FLEET MANAGEMENT REPORT")
    print(f"="*70)
    print(f"   Report Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"   Fleet Size: {len(fleet):,} vehicles")
    print(f"   Processing Mode: Enterprise Multi-Threading")
    
    # Fleet composition analysis
    print(f"\n FLEET COMPOSITION ANALYSIS:")
    
    # Model distribution
    model_counts = {}
    for vehicle in fleet:
        model_counts[vehicle.model] = model_counts.get(vehicle.model, 0) + 1
    
    print(f"   Tesla Model Distribution:")
    for model, count in sorted(model_counts.items(), key=lambda x: x[1], reverse=True):
        percentage = count / len(fleet) * 100
        print(f"   {model:12} {count:6,} vehicles ({percentage:5.1f}%)")
    
    # Health status analysis
    health_dist = processing_results['processing_summary']['health_distribution']
    print(f"\n FLEET HEALTH STATUS:")
    for status, count in health_dist.items():
        percentage = count / len(fleet) * 100
        emoji = "âœ…" if status == "NORMAL" else "âš ï¸" if status == "WARNING" else "ðŸš¨"
        print(f"   {emoji} {status:8} {count:6,} vehicles ({percentage:5.1f}%)")
    
    # Performance metrics
    perf = processing_results['performance_metrics']
    print(f"\nâš¡ PROCESSING PERFORMANCE:")
    print(f"   Total Processing Time: {perf['total_time']:.1f} seconds")
    print(f"   Throughput: {perf['throughput_per_second']:.1f} vehicles/second")
    print(f"   Average Latency: {perf['average_latency_ms']:.2f} ms")
    print(f"   Peak Latency: {perf['peak_latency_ms']:.2f} ms")
    print(f"   Error Rate: {(perf['error_count']/perf['total_processed']*100):.2f}%")
    
    # Anomaly analysis
    anomaly_stats = processing_results['processing_summary']['anomaly_statistics']
    print(f"\n ANOMALY DETECTION ANALYSIS:")
    print(f"   Mean Anomaly Score: {anomaly_stats['mean_score']:.3f}")
    print(f"   Median Anomaly Score: {anomaly_stats['median_score']:.3f}")
    print(f"   Std Deviation: {anomaly_stats['std_score']:.3f}")
    print(f"   Highest Risk Vehicle: {anomaly_stats['max_score']:.3f}")
    print(f"   Vehicles Requiring Attention: {anomaly_stats['vehicles_over_threshold']:,}")
    
    # Production scalability assessment
    print(f"\n PRODUCTION SCALABILITY ASSESSMENT:")
    
    # Calculate scaling metrics
    vehicles_per_hour = perf['throughput_per_second'] * 3600
    daily_capacity = vehicles_per_hour * 24
    
    print(f"   Current Capacity: {vehicles_per_hour:,.0f} vehicles/hour")
    print(f"   Daily Processing: {daily_capacity:,.0f} vehicles/day")
    print(f"   Global Fleet Scale: {len(fleet):,} vehicles processed")
    
    # Scaling recommendations
    if perf['throughput_per_second'] > 50:
        scale_grade = "A+ EXCELLENT"
        scale_status = " Ready for global Tesla fleet"
    elif perf['throughput_per_second'] > 25:
        scale_grade = "B+ GOOD"
        scale_status = " Suitable with optimization"
    else:
        scale_grade = "C+ NEEDS IMPROVEMENT"
        scale_status = "âš  Requires infrastructure scaling"
    
    print(f"   Scalability Grade: {scale_grade}")
    print(f"   Production Status: {scale_status}")
    
    print(f"\n TESLA DEPLOYMENT RECOMMENDATIONS:")
    
    if perf['average_latency_ms'] < 30:
        print(f"    Real-time Processing: Suitable for live vehicle monitoring")
    else:
        print(f"    Batch Processing: Optimize for real-time deployment")
    
    if anomaly_stats['vehicles_over_threshold'] / len(fleet) < 0.1:
        print(f"    Fleet Health: Excellent overall vehicle condition")
    else:
        print(f"   âš  Fleet Health: {(anomaly_stats['vehicles_over_threshold']/len(fleet)*100):.1f}% require attention")
    
    print(f"\n ENTERPRISE ARCHITECTURE INSIGHTS:")
    print(f"    Demonstrated multi-threading scalability")
    print(f"    Production-grade error handling and monitoring")
    print(f"    Geographic distribution capability")
    print(f"    Real-time performance metrics collection")
    print(f"    Enterprise-scale data processing (1000+ entities)")
    
    print(f"\n" + "="*70)

def main():
    """Tesla Fleet Manager Main Application"""
    
    print(" Tesla Global Fleet Manager - Enterprise Scale Demonstration")
    print("=" * 70)
    print("Simulating Tesla's global vehicle monitoring at production scale")
    print()
    
    # Configuration
    FLEET_SIZE = 1500  # Simulate 1500 Tesla vehicles globally
    MAX_WORKERS = 25   # Parallel processing threads
    
    print(f" Configuration:")
    print(f"   Fleet Size: {FLEET_SIZE:,} vehicles")
    print(f"   Processing Threads: {MAX_WORKERS}")
    print(f"   Geographic Markets: Global distribution")
    print()
    
    # Generate Tesla fleet
    fleet_generator = TeslaFleetGenerator(FLEET_SIZE)
    tesla_fleet = fleet_generator.generate_fleet()
    
    # Process fleet diagnostics
    print(f"\nðŸ”§ Starting Tesla Fleet Diagnostic Processing...")
    fleet_processor = TeslaFleetProcessor(max_workers=MAX_WORKERS)
    
    processing_start = time.time()
    results = fleet_processor.process_fleet_parallel(tesla_fleet)
    processing_end = time.time()
    
    print(f"\n Fleet processing completed in {processing_end - processing_start:.1f} seconds")
    
    # Generate comprehensive report
    create_fleet_report(tesla_fleet, results)
    
    # Save results for further analysis
    output_data = {
        'fleet_summary': {
            'total_vehicles': len(tesla_fleet),
            'processing_time': processing_end - processing_start,
            'timestamp': datetime.now().isoformat()
        },
        'performance_metrics': results['performance_metrics'],
        'processing_summary': results['processing_summary']
    }
    
    with open('tesla_fleet_analysis.json', 'w') as f:
        json.dump(output_data, f, indent=2, default=str)
    
    print(f"\n Results saved to: tesla_fleet_analysis.json")
    print(f"\n Tesla Fleet Management Demonstration Complete!")
    print(f" Successfully demonstrated enterprise-scale vehicle monitoring capability")

if __name__ == "__main__":
    main()